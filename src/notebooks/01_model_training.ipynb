{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5341a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier  # <-- NEW MODEL\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721b3bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 'IMDB Dataset.csv' not found.\n",
      "Original size: 50000. Sampling down to 10,000 rows.\n",
      "Using 10000 reviews for training.\n",
      "                                                    text  sentiment\n",
      "33553  I really liked this Summerslam due to the look...          1\n",
      "9427   Not many television shows appeal to quite as m...          1\n",
      "199    The film quickly gets to a major chase scene w...          0\n",
      "12447  Jane Austen would definitely approve of this o...          1\n",
      "39489  Expectations were somewhat high for me when I ...          0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    # This path works INSIDE the Docker container\n",
    "    df = pd.read_csv('/data/IMDB Dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    # This path works for LOCAL execution (from the project root)\n",
    "    print(\"ERROR: 'IMDB Dataset.csv' not found.\")\n",
    "    df = pd.read_csv('../../data/IMDB Dataset.csv')\n",
    "\n",
    "# Map sentiment labels to 0 and 1 (matching our old model)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Rename 'review' column to 'text' to match our original code\n",
    "df = df.rename(columns={'review': 'text'})\n",
    "\n",
    "# --- NEW LINE ---\n",
    "# Subsample the data to prevent OOM errors in CI\n",
    "# We'll use 10,000 rows, which is plenty for a CI run\n",
    "if len(df) > 10000:\n",
    "    print(f\"Original size: {len(df)}. Sampling down to 10,000 rows.\")\n",
    "    df = df.sample(n=10000, random_state=42)\n",
    "# --- END NEW LINE ---\n",
    "\n",
    "print(f\"Using {len(df)} reviews for training.\")\n",
    "print(df.head())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea705b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Dev\\GitHub\\giga-flow-mlops\\src\\notebooks\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 302, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 395, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1303, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1296, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 303, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Dev\\GitHub\\giga-flow-mlops\\src\\notebooks\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 1: Model Training and MLflow Integration...\n",
      "Training SGDClassifier...\n",
      "Training complete.\n",
      "Evaluating model...\n",
      "Saving training data as artifact...\n",
      "Training data artifact saved.\n",
      "Logging model to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\GitHub\\giga-flow-mlops\\.venv\\Lib\\site-packages\\mlflow\\models\\signature.py:369: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MLflow Run Complete ---\n",
      "Run ID: 441d7aedac7f440fbd6915e58e57988f\n",
      "Logged Metrics: Accuracy=0.8860, F1-Score=0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'giga-flow-sentiment' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'giga-flow-sentiment'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Phase 1: Model Training and MLflow Integration...\")\n",
    "mlflow.set_experiment(\"GigaFlow-Sentiment\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # --- 1. Model Training ---\n",
    "    \n",
    "    params = {\n",
    "        \"loss\": \"hinge\",\n",
    "        \"penalty\": \"l2\",\n",
    "        \"alpha\": 1e-4, # Slightly stronger regularization\n",
    "        \"random_state\": 42,\n",
    "        \"max_iter\": 100\n",
    "    }\n",
    "\n",
    "    # Define the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2)), 'text')\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Create the full pipeline with the new model\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', SGDClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    print(\"Training SGDClassifier...\")\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- 2. MLflow Integration (Logging) ---\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"model_type\", \"SGDClassifier_with_TFIDF\")\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    preds = model_pipeline.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average='weighted')\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    print(\"Saving training data as artifact...\")\n",
    "    # We save X_train as a parquet file. It's efficient.\n",
    "    X_train.to_parquet(\"training_data.parquet\", index=False)\n",
    "\n",
    "    # Log the parquet file to MLflow in a folder named 'reference_data'\n",
    "    mlflow.log_artifact(\"training_data.parquet\", \"reference_data\")\n",
    "    print(\"Training data artifact saved.\")\n",
    "    \n",
    "    # Log the final model artifact\n",
    "    print(\"Logging model to MLflow...\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=X_train.iloc[:1],\n",
    "        registered_model_name=\"giga-flow-sentiment\"\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"\\n--- MLflow Run Complete ---\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Logged Metrics: Accuracy={acc:.4f}, F1-Score={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4f9a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Phase 1.3: Local Testing ---\n",
      "Loading model from Run ID: 441d7aedac7f440fbd6915e58e57988f\n",
      "\n",
      "--- Inference Results ---\n",
      "Input: This is a truly wonderful and amazing product -> Prediction: Positive\n",
      "Input: I am so angry and frustrated with this. -> Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Starting Phase 1.3: Local Testing ---\")\n",
    "print(f\"Loading model from Run ID: {run_id}\")\n",
    "\n",
    "logged_model_uri = f\"runs:/{run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"This is a truly wonderful and amazing product\",\n",
    "        \"I am so angry and frustrated with this.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "predictions = loaded_model.predict(test_data)\n",
    "\n",
    "print(\"\\n--- Inference Results ---\")\n",
    "print(f\"Input: {test_data['text'].iloc[0]} -> Prediction: {'Positive' if predictions[0] == 1 else 'Negative'}\")\n",
    "print(f\"Input: {test_data['text'].iloc[1]} -> Prediction: {'Positive' if predictions[1] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2aa4878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Phase 1.4: Register Model ---\n",
      "Registered Model: giga-flow-sentiment, Version: 5\n",
      "Run ID: 441d7aedac7f440fbd6915e58e57988f\n",
      "Model successfully registered. Promotion will be handled by the CI/CD pipeline.\n",
      "MLFLOW_RUN_ID=441d7aedac7f440fbd6915e58e57988f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_4472\\32581828.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  latest_version = client.get_latest_versions(model_name, stages=None)[0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Starting Phase 1.4: Register Model ---\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"giga-flow-sentiment\"\n",
    "\n",
    "# Get the latest version that was just registered\n",
    "latest_version = client.get_latest_versions(model_name, stages=None)[0]\n",
    "version_number = latest_version.version\n",
    "\n",
    "print(f\"Registered Model: {model_name}, Version: {version_number}\")\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(\"Model successfully registered. Promotion will be handled by the CI/CD pipeline.\")\n",
    "\n",
    "# We also need to print the run_id so the GitHub Action can read it\n",
    "print(f\"MLFLOW_RUN_ID={run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
