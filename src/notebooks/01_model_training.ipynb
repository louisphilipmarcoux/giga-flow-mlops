{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlflow.tracking import MlflowClient\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    # This path works INSIDE the Docker container\n",
    "    df = pd.read_csv('/data/IMDB Dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    # This path works for LOCAL execution (from the project root)\n",
    "    print(\"ERROR: 'IMDB Dataset.csv' not found.\")\n",
    "    df = pd.read_csv('../../data/IMDB Dataset.csv')\n",
    "\n",
    "# Map sentiment labels to 0 and 1 (matching our old model)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Rename 'review' column to 'text' to match our original code\n",
    "df = df.rename(columns={'review': 'text'})\n",
    "\n",
    "# --- MODIFIED SAMPLING LOGIC --- [cite: 19, 20]\n",
    "# Check for an env var. Default to 'CI' if not set.\n",
    "TRAINING_MODE = os.getenv(\"TRAINING_MODE\", \"CI\")\n",
    "\n",
    "# Only sample down if in 'CI' mode\n",
    "if TRAINING_MODE == \"CI\" and len(df) > 10000:\n",
    "    print(f\"CI Mode: Sampling down to 10,000 rows.\")\n",
    "    df = df.sample(n=10000, random_state=42)\n",
    "else:\n",
    "    print(f\"FULL Mode: Using all {len(df)} rows for training.\")\n",
    "# --- END MODIFIED LOGIC ---\n",
    "\n",
    "print(f\"Using {len(df)} reviews for training.\")\n",
    "print(df.head())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea705b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Define the Hugging Face model we want to use \n",
    "HF_MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "mlflow.set_experiment(\"GigaFlow-Sentiment\")\n",
    "\n",
    "# 2. Define a custom MLflow PythonModel wrapper\n",
    "# This is the key to making the new model \"work seamlessly\" \n",
    "# It ensures the model.predict() output is 0 or 1, just like the old model.\n",
    "class HfSentimentWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # Load the pre-trained pipeline with truncation enabled\n",
    "        self.pipeline = pipeline(\n",
    "            \"sentiment-analysis\", \n",
    "            model=HF_MODEL_NAME, \n",
    "            tokenizer=HF_MODEL_NAME,\n",
    "            device=0 if torch.cuda.is_available() else -1,  # Use GPU if present\n",
    "            truncation=True,  # ADD THIS LINE\n",
    "            max_length=512    # ADD THIS LINE\n",
    "        )\n",
    "\n",
    "    def predict(self, context, model_input, batch_size=32):\n",
    "        # model_input is a pandas DataFrame\n",
    "        text_list = model_input['text'].tolist()\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Process in batches\n",
    "        num_batches = math.ceil(len(text_list) / batch_size)\n",
    "        for i in range(num_batches):\n",
    "            batch = text_list[i*batch_size : (i+1)*batch_size]\n",
    "            \n",
    "            # Run inference on the batch\n",
    "            preds_raw = self.pipeline(batch, truncation=True, max_length=512)  # ADD truncation=True, max_length=512\n",
    "            \n",
    "            # Convert output to 0 or 1\n",
    "            preds = [1 if p['label'] == 'POSITIVE' else 0 for p in preds_raw]\n",
    "            results.extend(preds)\n",
    "            \n",
    "        return pd.Series(results)\n",
    "\n",
    "print(\"Starting Phase 1: Model Training and MLflow Integration...\")\n",
    "\n",
    "# 3. Start the MLflow Run\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    print(f\"Logging parameters for {HF_MODEL_NAME}\")\n",
    "    mlflow.log_param(\"model_type\", \"HuggingFace_Transformer\")\n",
    "    mlflow.log_param(\"model_name\", HF_MODEL_NAME)\n",
    "    mlflow.log_param(\"max_sequence_length\", 512)  # ADD THIS LINE\n",
    "    mlflow.log_param(\"truncation\", True)  # ADD THIS LINE\n",
    "\n",
    "    # --- 4. Evaluate the new model ---\n",
    "    # We must evaluate it to get metrics *before* logging the model\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    \n",
    "    # Create a temporary pipeline for evaluation with truncation enabled\n",
    "    temp_pipeline = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=HF_MODEL_NAME,\n",
    "        tokenizer=HF_MODEL_NAME,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        truncation=True,  # ADD THIS LINE\n",
    "        max_length=512    # ADD THIS LINE\n",
    "    )\n",
    "    \n",
    "    preds = []\n",
    "    batch_size = 32\n",
    "    test_texts = X_test['text'].tolist()\n",
    "    \n",
    "    num_batches = math.ceil(len(test_texts) / batch_size)\n",
    "    print(f\"Evaluating {len(test_texts)} test samples in {num_batches} batches...\")\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch = test_texts[i*batch_size : (i+1)*batch_size]\n",
    "        # Add truncation to the pipeline call as well\n",
    "        preds_raw = temp_pipeline(batch, truncation=True, max_length=512)  # ADD truncation=True, max_length=512\n",
    "        preds.extend([1 if p['label'] == 'POSITIVE' else 0 for p in preds_raw])\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average='weighted')\n",
    "    \n",
    "    print(f\"Evaluation complete: Accuracy={acc:.4f}, F1-Score={f1:.4f}\")\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # --- 5. Log the custom wrapper as the model ---\n",
    "    print(\"Saving training data as artifact...\")\n",
    "    X_train.to_parquet(\"training_data.parquet\", index=False)\n",
    "    mlflow.log_artifact(\"training_data.parquet\", \"reference_data\")\n",
    "    print(\"Training data artifact saved.\")\n",
    "\n",
    "    print(\"Logging model to MLflow...\")\n",
    "    \n",
    "    # Define the environment for the model\n",
    "    conda_env = {\n",
    "        'channels': ['defaults', 'conda-forge'],\n",
    "        'dependencies': [\n",
    "            f'python=3.11', # Match your Dockerfile\n",
    "            'pip',\n",
    "            {\n",
    "                'pip': [\n",
    "                    'mlflow',\n",
    "                    'pandas',\n",
    "                    'torch',\n",
    "                    'transformers',\n",
    "                    'accelerate'\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Log the custom PyFunc model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=HfSentimentWrapper(),\n",
    "        input_example=X_train.iloc[:5],\n",
    "        registered_model_name=\"giga-flow-sentiment\",\n",
    "        conda_env=conda_env\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"\\n--- MLflow Run Complete ---\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Logged Metrics: Accuracy={acc:.4f}, F1-Score={f1:.4f}\")\n",
    "\n",
    "    # We also need to print the run_id so the GitHub Action can read it\n",
    "    print(f\"MLFLOW_RUN_ID={run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Starting Phase 1.3: Local Testing ---\")\n",
    "print(f\"Loading model from Run ID: {run_id}\")\n",
    "\n",
    "logged_model_uri = f\"runs:/{run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"This is a truly wonderful and amazing product\",\n",
    "        \"I am so angry and frustrated with this.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "predictions = loaded_model.predict(test_data)\n",
    "\n",
    "print(\"\\n--- Inference Results ---\")\n",
    "print(f\"Input: {test_data['text'].iloc[0]} -> Prediction: {'Positive' if predictions[0] == 1 else 'Negative'}\")\n",
    "print(f\"Input: {test_data['text'].iloc[1]} -> Prediction: {'Positive' if predictions[1] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Starting Phase 1.4: Register Model ---\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"giga-flow-sentiment\"\n",
    "\n",
    "# Get the latest version that was just registered\n",
    "latest_version = client.get_latest_versions(model_name, stages=None)[0]\n",
    "version_number = latest_version.version\n",
    "\n",
    "print(f\"Registered Model: {model_name}, Version: {version_number}\")\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(\"Model successfully registered. Promotion will be handled by the CI/CD pipeline.\")\n",
    "\n",
    "# We also need to print the run_id so the GitHub Action can read it\n",
    "print(f\"MLFLOW_RUN_ID={run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
