{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier  # <-- NEW MODEL\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('/data/IMDB Dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'IMDB Dataset.csv' not found.\")\n",
    "    print(\"Please download it from Kaggle and place it in the 'data/' directory.\")\n",
    "    # We'll re-run this from inside Docker, where the path will be correct\n",
    "    # For local testing, make sure your notebook is running from the project root\n",
    "    # and the file is at './data/IMDB Dataset.csv'\n",
    "    df = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "\n",
    "# Map sentiment labels to 0 and 1 (matching our old model)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Rename 'review' column to 'text' to match our original code\n",
    "df = df.rename(columns={'review': 'text'})\n",
    "\n",
    "print(f\"Loaded {len(df)} reviews.\")\n",
    "print(df.head())\n",
    "\n",
    "# Split the data (using a 20% test size for a large dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea705b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Phase 1: Model Training and MLflow Integration...\")\n",
    "mlflow.set_experiment(\"GigaFlow-Sentiment\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # --- 1. Model Training ---\n",
    "    \n",
    "    params = {\n",
    "        \"loss\": \"hinge\",\n",
    "        \"penalty\": \"l2\",\n",
    "        \"alpha\": 1e-4, # Slightly stronger regularization\n",
    "        \"random_state\": 42,\n",
    "        \"max_iter\": 100\n",
    "    }\n",
    "\n",
    "    # Define the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2)), 'text')\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Create the full pipeline with the new model\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', SGDClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    print(\"Training SGDClassifier...\")\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- 2. MLflow Integration (Logging) ---\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"model_type\", \"SGDClassifier_with_TFIDF\")\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    preds = model_pipeline.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average='weighted')\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log the final model artifact\n",
    "    print(\"Logging model to MLflow...\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=X_train.iloc[:1],\n",
    "        registered_model_name=\"giga-flow-sentiment\"\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"\\n--- MLflow Run Complete ---\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Logged Metrics: Accuracy={acc:.4f}, F1-Score={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Starting Phase 1.3: Local Testing ---\")\n",
    "print(f\"Loading model from Run ID: {run_id}\")\n",
    "\n",
    "logged_model_uri = f\"runs:/{run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"This is a truly wonderful and amazing product\",\n",
    "        \"I am so angry and frustrated with this.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "predictions = loaded_model.predict(test_data)\n",
    "\n",
    "print(\"\\n--- Inference Results ---\")\n",
    "print(f\"Input: {test_data['text'].iloc[0]} -> Prediction: {'Positive' if predictions[0] == 1 else 'Negative'}\")\n",
    "print(f\"Input: {test_data['text'].iloc[1]} -> Prediction: {'Positive' if predictions[1] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Starting Phase 1.4: Register Model and Set Alias ---\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"giga-flow-sentiment\"\n",
    "model_alias = \"champion\"\n",
    "\n",
    "latest_version = client.get_latest_versions(model_name, stages=None)[0]\n",
    "version_number = latest_version.version\n",
    "\n",
    "print(f\"Registered Model: {model_name}, Version: {version_number}\")\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=model_alias,\n",
    "    version=version_number\n",
    ")\n",
    "\n",
    "print(f\"Alias '{model_alias}' set for {model_name} version {version_number}.\")\n",
    "print(\"Model successfully registered and aliased for deployment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
